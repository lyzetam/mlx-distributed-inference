# Home Assistant Training Configuration for Gemma 9B

# Model configuration
model:
  name: "mlx-community/gemma-2-9b-it-4bit"  # Quantized version for MLX
  # Alternative options:
  # name: "google/gemma-2-9b-it"  # Full precision (needs more memory)
  # name: "google/gemma-2-9b"  # Base model

# Training type
training:
  type: "lora"  # LoRA for efficient fine-tuning
  
  # LoRA parameters optimized for 9B model
  lora:
    rank: 16      # Higher rank for better capacity
    alpha: 32     # Alpha = 2 * rank is a good default
    dropout: 0.1  # Small dropout for regularization
    scale: 10.0
    num_layers: 16  # Apply LoRA to more layers for 9B model

# Dataset configuration
dataset:
  path: "data/homeassistant_training.jsonl"
  output_dir: "data"
  validation_split: 0.1  # 10% for validation
  max_seq_length: 512   # Shorter sequences for efficiency
  format_type: "chat"
  shuffle: true
  seed: 42

# Training hyperparameters
hyperparameters:
  batch_size: 1         # Small batch size for 9B model
  learning_rate: 5e-5   # Lower learning rate for larger model
  num_iterations: 100   # Quick test run
  val_batches: 10       # Fewer validation batches for speed
  steps_per_report: 5   # More frequent reporting
  steps_per_eval: 20    # More frequent evaluation
  gradient_accumulation_steps: 4  # Simulate larger batch size
  warmup_steps: 10
  weight_decay: 0.01
  
  # Learning rate schedule
  lr_schedule: "cosine"  # Cosine annealing

# Checkpointing
checkpointing:
  save_every: 50  # Save more frequently for test run
  output_dir: "adapters/homeassistant_gemma9b"
  resume_from: null

# Distributed training
distributed:
  enabled: true  # Set to true if using multiple nodes
  backend: "mpi"
  
# Logging
logging:
  level: "INFO"
  log_file: "logs/homeassistant_training.log"
  
# Evaluation
evaluation:
  test_prompts:
    - "turn on the bedroom lights"
    - "can you please dim the living room to 50 percent"
    - "what's the temperature in the kitchen"
    - "lock the front door"
    - "activate movie mode"
    - "turn off all lights please"
  max_tokens: 150  # Longer for structured responses

# Memory optimization
optimization:
  gradient_checkpointing: true  # Essential for 9B model
  mixed_precision: false  # Keep false for stability

(mlx-env) mm@mm1 mlx-project % mlx.launch \
  --hosts 10.85.100.221,10.85.100.222 \
  python3 distributed_inference_mlx.py \
    --max-tokens 128 \
    --model-name TinyLlama/TinyLlama-1.1B-Chat-v1.0 \
    "What is the meaning of life?"


(mlx-env) mm@mm1 mlx-project % mlx.launch \
  --hostfile hosts.json \
  --backend ring \
  python3 distributed_inference_mlx.py \
    --max-tokens 128 \
    --model-name TinyLlama/TinyLlama-1.1B-Chat-v1.0 \
    "What is the meaning of life?"

mlx.launch \
--hosts 10.85.100.221,10.85.100.222 \
python3 distributed_inference_mlx.py \
--max-tokens 32 \
--model-name mlx-community/DeepSeek-R1-Qwen3-0528-8B-4bit-AWQ \
"What is the meaning of life?"